# XREAL AR Glasses Development Guide

## Overview

This guide provides comprehensive technical documentation for developing applications with XREAL AR glasses, covering hardware protocols, driver integration, software architecture, and performance optimization techniques.

## Hardware Architecture

### USB-C Communication Protocol

XREAL glasses use a sophisticated USB-C communication architecture:

- **Dual Bus Design**: Utilizes both USB2 and USB3 buses simultaneously
- **DisplayPort Integration**: 2-lane DisplayPort support, limiting bandwidth to 1080p@60
- **HID Communication**: Uses Human Interface Device protocol for device control and sensor data

### IMU Data Communication

The IMU system operates through a specialized HID-based protocol:

#### Activation Command
```rust
// Command to enable IMU streaming
let enable_imu = [0x02, 0x19, 0x01];
```

#### Data Packet Structure
- **Timestamps**: Separate timestamps for gyroscope and accelerometer
- **Precision Control**: Multiplier and divisor values for precise sensor calculations
- **Sensor Readings**: Raw accelerometer, gyroscope, and magnetometer data

#### Conversion Formulas
```rust
// Gyroscope (rad/s)
let gyro_rad_per_sec = (raw_value * multiplier) / divisor;

// Accelerometer (m/sÂ²)
let accel_m_per_s2 = (raw_value * multiplier) / divisor;
```

### Display Control Protocol

Display management uses ASCII-based commands with specific formatting:

- **Command Format**: Start/end text markers
- **Mode Control**: Support for 2D, 3D, and 3D@72Hz modes
- **Heartbeat Requirement**: Periodic "SDK works" messages to maintain display functionality
- **Calibration Integration**: Retrieval of device-specific calibration files

## Driver Layer (ar-drivers-rs)

### Supported Devices
- XREAL Air, Air 2, Air 2 Pro
- XREAL Light
- Rokid Air and Max
- Grawoow G530 (Metavision M53)
- Mad Gaze Glow

### Architecture Principles

#### Device-Agnostic Design
```rust
// Unified interface across different AR glasses
pub trait ARGlasses {
    fn get_sensor_data(&self) -> Result<SensorData>;
    fn set_display_mode(&self, mode: DisplayMode) -> Result<()>;
    fn set_brightness(&self, level: u8) -> Result<()>;
}
```

#### Performance Optimizations
- **HIDAPI Usage**: More performant than libusb for HID communication
- **Static Linking**: Enables portable executables
- **libudev Integration**: Efficient device detection and management

### Core Capabilities
- Basic sensor data retrieval
- Display setup and configuration
- Mode switching (particularly 3D SBS mode)
- Device enumeration and identification

## Software Architecture

### Bevy ECS Integration

#### AsyncComputeTaskPool Pattern
```rust
use bevy::tasks::{AsyncComputeTaskPool, Task};
use bevy::ecs::world::CommandQueue;

#[derive(Component)]
struct IMUTask(Task<CommandQueue>);

fn spawn_imu_task(mut commands: Commands) {
    let thread_pool = AsyncComputeTaskPool::get();
    let task = thread_pool.spawn(async move {
        let mut command_queue = CommandQueue::default();
        
        // Async IMU processing
        if let Ok(orientation) = poll_imu_data().await {
            command_queue.push(move |world: &mut World| {
                // Update ECS world with new orientation
            });
        }
        
        command_queue
    });
    
    commands.spawn(IMUTask(task));
}
```

#### Resource Management
```rust
#[derive(Resource)]
struct Orientation {
    pub quat: Quat,
}

#[derive(Resource)]
struct CalibrationState {
    // Calibration data and state
}
```

### Thread Safety Considerations

#### Channel Communication
```rust
// Use crossbeam for Sync compatibility with Bevy resources
use crossbeam_channel::{bounded, Receiver, Sender};

#[derive(Resource, Deref)]
struct DataReceiver(Receiver<OrientationData>);

#[derive(Resource)]
struct CommandSender(Sender<IMUCommand>);
```

#### Async-to-ECS Communication
```rust
fn handle_imu_tasks(
    mut commands: Commands,
    mut tasks: Query<&mut IMUTask>,
) {
    use bevy::tasks::{futures_lite::future, block_on};
    
    for mut task in &mut tasks {
        // Non-blocking poll
        if let Some(mut command_queue) = block_on(future::poll_once(&mut task.0)) {
            commands.append(&mut command_queue);
        }
    }
}
```

## Bevy Plugin System for XREAL Applications

Bevy's plugin system provides a powerful, first-class architecture for building modular, reusable components. For XREAL applications, proper plugin design enables clean separation of concerns, maintainable codebases, and extensible functionality while maintaining the jitter-free performance requirements.

### Plugin Architecture Fundamentals

#### The Plugin Trait

All Bevy plugins implement the `Plugin` trait with a single required method:

```rust
use bevy::prelude::*;

pub struct XRealTrackingPlugin {
    pub calibration_samples: usize,
    pub jitter_threshold: f32,
}

impl Plugin for XRealTrackingPlugin {
    fn build(&self, app: &mut App) {
        app
            // Register resources
            .insert_resource(CalibrationState::default())
            .insert_resource(JitterMetrics::<1000>::default())
            
            // Register systems
            .add_systems(Startup, setup_tracking_resources)
            .add_systems(FixedUpdate, (
                process_imu_data,
                monitor_jitter_metrics,
                update_calibration_state,
            ).chain())
            
            // Register events
            .add_event::<TrackingEvent>()
            
            // Configure system sets for ordering
            .configure_sets(FixedUpdate, 
                TrackingSystemSet::Processing
                    .before(TrackingSystemSet::Output)
            );
    }
}

// System sets for precise ordering
#[derive(SystemSet, Debug, Hash, PartialEq, Eq, Clone)]
pub enum TrackingSystemSet {
    Processing,
    Output,
}
```

#### Plugin Registration Patterns

XREAL plugins integrate with the main application builder in `src/main.rs`:

```rust
// src/main.rs integration example
fn main() -> Result<()> {
    App::new()
        // Core Bevy plugins
        .add_plugins(DefaultPlugins.set(WindowPlugin {
            primary_window: Some(Window {
                title: "XREAL Virtual Desktop".into(),
                resolution: (450., 350.).into(),
                // ... window configuration
            }),
            ..default()
        }))
        
        // XREAL-specific plugins
        .add_plugins((
            XRealTrackingPlugin {
                calibration_samples: 5000,
                jitter_threshold: 1.0,
            },
            XRealRenderPlugin::default(),
            XRealUIPlugin::with_theme(CyrupTheme::default()),
        ))
        
        // Third-party plugins
        .add_plugins(EguiPlugin::default())
        .add_plugins(FrameTimeDiagnosticsPlugin::default())
        
        .run();
    
    Ok(())
}
```

### XREAL Plugin Implementation Patterns

#### Resource Integration Plugin

Plugins that integrate with existing XREAL resources should follow this pattern:

```rust
pub struct XRealDisplayPlugin {
    pub default_mode: DisplayMode,
    pub brightness_level: u8,
}

impl Plugin for XRealDisplayPlugin {
    fn build(&self, app: &mut App) {
        // Initialize resources if they don't exist
        if !app.world().contains_resource::<DisplayModeState>() {
            app.insert_resource(DisplayModeState {
                is_3d_enabled: matches!(self.default_mode, DisplayMode::Stereo),
                pending_change: None,
            });
        }
        
        if !app.world().contains_resource::<BrightnessState>() {
            app.insert_resource(BrightnessState {
                current_level: self.brightness_level,
                pending_change: None,
            });
        }
        
        // Add systems that work with existing infrastructure
        app.add_systems(FixedUpdate, (
            display_mode_system.in_set(XRealSystemSets::Hardware),
            brightness_control_system.in_set(XRealSystemSets::Hardware),
        ));
    }
}

// System sets for XREAL-wide coordination
#[derive(SystemSet, Debug, Hash, PartialEq, Eq, Clone)]
pub enum XRealSystemSets {
    Input,
    Processing,
    Hardware,
    Rendering,
    UI,
}
```

#### Head Tracking Access Plugin

Plugins that need head tracking data should use this safe access pattern:

```rust
pub struct XRealSpatialAudioPlugin {
    pub max_distance: f32,
    pub doppler_factor: f32,
}

impl Plugin for XRealSpatialAudioPlugin {
    fn build(&self, app: &mut App) {
        app
            .insert_resource(SpatialAudioConfig {
                max_distance: self.max_distance,
                doppler_factor: self.doppler_factor,
            })
            .add_systems(FixedUpdate, 
                update_spatial_audio
                    .in_set(XRealSystemSets::Processing)
                    .after(XRealSystemSets::Input)
            );
    }
}

fn update_spatial_audio(
    orientation: Res<Orientation>,
    audio_config: Res<SpatialAudioConfig>,
    mut audio_sources: Query<(&mut Transform, &AudioSource3D)>,
) {
    let head_rotation = orientation.quat;
    
    for (mut transform, audio_source) in audio_sources.iter_mut() {
        // Calculate 3D audio positioning based on head orientation
        let relative_position = head_rotation.inverse() * audio_source.world_position;
        transform.translation = relative_position.truncate();
        
        // Apply distance-based attenuation
        let distance = transform.translation.length();
        if distance > audio_config.max_distance {
            // Audio source is too far, mute it
            transform.scale = Vec3::ZERO;
        } else {
            let attenuation = 1.0 - (distance / audio_config.max_distance);
            transform.scale = Vec3::splat(attenuation);
        }
    }
}
```

### Plugin Development Best Practices

#### Error Handling Within Plugins

XREAL plugins must maintain the jitter-free guarantee through robust error handling:

```rust
pub struct XRealNetworkPlugin {
    pub connection_timeout: Duration,
    pub retry_attempts: u32,
}

impl Plugin for XRealNetworkPlugin {
    fn build(&self, app: &mut App) {
        app
            .insert_resource(NetworkConfig {
                timeout: self.connection_timeout,
                retries: self.retry_attempts,
            })
            .add_systems(FixedUpdate, 
                network_update_system.in_set(XRealSystemSets::Processing)
            )
            .add_event::<NetworkEvent>();
    }
}

fn network_update_system(
    config: Res<NetworkConfig>,
    mut network_state: ResMut<NetworkState>,
    mut events: EventWriter<NetworkEvent>,
) {
    // Never use unwrap() or expect() in XREAL systems
    match network_state.connection.as_mut() {
        Some(connection) => {
            // Check connection health without blocking
            match connection.try_recv_timeout(Duration::from_millis(1)) {
                Ok(data) => {
                    events.send(NetworkEvent::DataReceived(data));
                }
                Err(RecvTimeoutError::Timeout) => {
                    // No data available, continue normally
                }
                Err(RecvTimeoutError::Disconnected) => {
                    warn!("Network connection lost, attempting reconnect");
                    network_state.connection = None;
                    events.send(NetworkEvent::ConnectionLost);
                }
            }
        }
        None => {
            // Attempt non-blocking reconnection
            if network_state.should_retry() {
                match NetworkConnection::try_connect(config.timeout) {
                    Ok(connection) => {
                        network_state.connection = Some(connection);
                        events.send(NetworkEvent::Connected);
                    }
                    Err(e) => {
                        debug!("Network reconnection failed: {}, retrying later", e);
                        network_state.increment_retry();
                    }
                }
            }
        }
    }
}
```

#### Performance-Conscious Plugin Design

Plugins must integrate with XREAL's jitter measurement and performance monitoring:

```rust
pub struct XRealPerformancePlugin {
    pub frame_time_budget: Duration,
    pub memory_limit_mb: u64,
}

impl Plugin for XRealPerformancePlugin {
    fn build(&self, app: &mut App) {
        app
            .insert_resource(PerformanceConfig {
                frame_budget: self.frame_time_budget,
                memory_limit: self.memory_limit_mb * 1024 * 1024,
            })
            .add_systems(FixedUpdate, (
                monitor_system_performance,
                enforce_performance_limits,
            ).chain().in_set(XRealSystemSets::Processing));
    }
}

fn monitor_system_performance(
    performance_config: Res<PerformanceConfig>,
    mut jitter_metrics: ResMut<JitterMetrics<1000>>,
    time: Res<Time>,
) {
    let current_frame_time = time.delta().as_secs_f32() * 1000.0; // Convert to ms
    
    // Integrate with existing jitter monitoring
    jitter_metrics.add_frame_measurement(current_frame_time);
    
    // Check if we're exceeding performance budget
    if current_frame_time > performance_config.frame_budget.as_secs_f32() * 1000.0 {
        warn!("â ï¸ Frame time budget exceeded: {:.2}ms (budget: {:.2}ms)", 
              current_frame_time, 
              performance_config.frame_budget.as_secs_f32() * 1000.0);
    }
}
```

### Advanced Plugin Patterns

#### Render Plugin Integration

Plugins that need custom rendering must integrate with Bevy's render world:

```rust
use bevy::render::{RenderApp, RenderSet};
use bevy::render::extract_resource::{ExtractResource, ExtractResourcePlugin};

pub struct XRealCustomRenderPlugin;

impl Plugin for XRealCustomRenderPlugin {
    fn build(&self, app: &mut App) {
        // Register in main world
        app
            .add_plugins(ExtractResourcePlugin::<XRealRenderData>::default())
            .insert_resource(XRealRenderData::default())
            .add_systems(Update, prepare_render_data);
        
        // Register in render world
        if let Some(render_app) = app.get_sub_app_mut(RenderApp) {
            render_app
                .add_systems(ExtractSchedule, extract_xreal_render_data)
                .add_systems(Render, 
                    xreal_custom_render.in_set(RenderSet::Queue)
                );
        }
    }
}

#[derive(Resource, Clone, ExtractResource)]
struct XRealRenderData {
    stereo_offset: f32,
    distortion_params: Vec4,
}

fn xreal_custom_render(
    render_data: Res<XRealRenderData>,
    render_device: Res<RenderDevice>,
    render_queue: Res<RenderQueue>,
) {
    // Custom XREAL rendering using WGPU resources
    // This integrates with the main render pipeline
}
```

#### UI Plugin Integration

Plugins that extend the UI must integrate with the CYRUP.ai theme system:

```rust
pub struct XRealDebugUIPlugin {
    pub show_performance: bool,
    pub show_tracking: bool,
}

impl Plugin for XRealDebugUIPlugin {
    fn build(&self, app: &mut App) {
        app
            .insert_resource(DebugUIState {
                show_performance: self.show_performance,
                show_tracking: self.show_tracking,
                is_visible: false,
            })
            .add_systems(Update, 
                debug_ui_system.after(reset_ui_guard)
            );
    }
}

fn debug_ui_system(
    mut contexts: EguiContexts,
    debug_state: Res<DebugUIState>,
    jitter_metrics: Res<JitterMetrics<1000>>,
    orientation: Res<Orientation>,
) {
    if !debug_state.is_visible {
        return;
    }
    
    let ctx = match contexts.try_ctx_mut() {
        Ok(ctx) => ctx,
        Err(_) => return,
    };
    
    // Apply CYRUP.ai theme (integrates with existing UI)
    CyrupTheme::apply_style(ctx);
    
    egui::Window::new("ð§ XREAL Debug")
        .default_size([300.0, 400.0])
        .show(ctx, |ui| {
            if debug_state.show_performance {
                ui.group(|ui| {
                    ui.label(
                        egui::RichText::new("ð Performance Metrics")
                            .color(CyrupTheme::ACCENT)
                            .strong()
                    );
                    
                    ui.label(format!("Frame Mean: {:.2}ms", jitter_metrics.frame_mean));
                    ui.label(format!("Frame StdDev: {:.2}ms", jitter_metrics.frame_std_dev()));
                    ui.label(format!("IMU Mean: {:.2}ms", jitter_metrics.imu_mean));
                    ui.label(format!("IMU StdDev: {:.2}ms", jitter_metrics.imu_std_dev()));
                });
            }
            
            if debug_state.show_tracking {
                ui.group(|ui| {
                    ui.label(
                        egui::RichText::new("ð¯ Head Tracking")
                            .color(CyrupTheme::ACCENT)
                            .strong()
                    );
                    
                    let euler = orientation.quat.to_euler(EulerRot::YXZ);
                    ui.label(format!("Yaw: {:.1}Â°", euler.0.to_degrees()));
                    ui.label(format!("Pitch: {:.1}Â°", euler.1.to_degrees()));
                    ui.label(format!("Roll: {:.1}Â°", euler.2.to_degrees()));
                });
            }
        });
}
```

### Plugin Communication and Dependencies

#### Event-Based Plugin Communication

Plugins should communicate through Bevy's event system for loose coupling:

```rust
// Define events for inter-plugin communication
#[derive(Event)]
pub enum XRealSystemEvent {
    CalibrationCompleted,
    TrackingLost,
    PerformanceWarning { metric: String, value: f32 },
    UserInteraction { action: String },
}

pub struct XRealEventBusPlugin;

impl Plugin for XRealEventBusPlugin {
    fn build(&self, app: &mut App) {
        app
            .add_event::<XRealSystemEvent>()
            .add_systems(FixedUpdate, (
                handle_calibration_events,
                handle_performance_events,
            ).in_set(XRealSystemSets::Processing));
    }
}

fn handle_calibration_events(
    mut events: EventReader<XRealSystemEvent>,
    mut ui_state: ResMut<SettingsPanelState>,
) {
    for event in events.read() {
        match event {
            XRealSystemEvent::CalibrationCompleted => {
                info!("â Calibration completed, updating UI");
                // Update UI state to reflect completion
            }
            XRealSystemEvent::TrackingLost => {
                warn!("â ï¸ Head tracking lost, showing recovery UI");
                ui_state.show_tracking_recovery = true;
            }
            _ => {}
        }
    }
}
```

#### Plugin Dependency Management

While Bevy doesn't have formal dependency resolution, use this pattern for plugin dependencies:

```rust
pub struct XRealApplicationPlugin {
    pub required_plugins: Vec<String>,
}

impl Plugin for XRealApplicationPlugin {
    fn build(&self, app: &mut App) {
        // Verify required resources exist (informal dependency checking)
        if !app.world().contains_resource::<Orientation>() {
            panic!("XRealApplicationPlugin requires XRealTrackingPlugin to be added first");
        }
        
        if !app.world().contains_resource::<SystemStatus>() {
            panic!("XRealApplicationPlugin requires XRealStatusPlugin to be added first");
        }
        
        // Safe to proceed with plugin initialization
        app.add_systems(FixedUpdate, application_main_loop);
    }
}

// Plugin group for managing dependencies
pub struct XRealCorePlugins;

impl PluginGroup for XRealCorePlugins {
    fn build(self) -> PluginGroupBuilder {
        PluginGroupBuilder::start::<Self>()
            // Order matters - dependencies first
            .add(XRealTrackingPlugin::default())
            .add(XRealStatusPlugin::default())
            .add(XRealDisplayPlugin::default())
            .add(XRealUIPlugin::default())
            // Application plugins that depend on core plugins
            .add(XRealApplicationPlugin::default())
    }
}
```

### Example XREAL Plugin Implementation

Here's a complete example of a well-structured XREAL plugin:

```rust
// src/plugins/screen_sharing.rs
use bevy::prelude::*;
use anyhow::Result;

pub struct XRealScreenSharingPlugin {
    pub max_clients: usize,
    pub compression_quality: f32,
}

impl Default for XRealScreenSharingPlugin {
    fn default() -> Self {
        Self {
            max_clients: 4,
            compression_quality: 0.8,
        }
    }
}

impl Plugin for XRealScreenSharingPlugin {
    fn build(&self, app: &mut App) {
        app
            // Resources
            .insert_resource(ScreenSharingConfig {
                max_clients: self.max_clients,
                quality: self.compression_quality,
            })
            .insert_resource(ScreenSharingState::default())
            
            // Events
            .add_event::<ScreenSharingEvent>()
            
            // Systems
            .add_systems(Startup, initialize_screen_sharing)
            .add_systems(FixedUpdate, (
                handle_client_connections,
                compress_screen_data,
                broadcast_to_clients,
            ).chain().in_set(XRealSystemSets::Processing))
            
            // UI integration
            .add_systems(Update, screen_sharing_ui.after(reset_ui_guard));
    }
}

#[derive(Resource)]
struct ScreenSharingConfig {
    max_clients: usize,
    quality: f32,
}

#[derive(Resource, Default)]
struct ScreenSharingState {
    active_clients: Vec<ClientConnection>,
    compression_buffer: Vec<u8>,
    last_frame_time: f32,
}

#[derive(Event)]
enum ScreenSharingEvent {
    ClientConnected(String),
    ClientDisconnected(String),
    CompressionComplete(Vec<u8>),
}

fn initialize_screen_sharing(mut commands: Commands) {
    // Initialize screen sharing resources
    info!("ð Initializing XREAL screen sharing plugin");
}

fn handle_client_connections(
    mut state: ResMut<ScreenSharingState>,
    config: Res<ScreenSharingConfig>,
    mut events: EventWriter<ScreenSharingEvent>,
) {
    // Handle new client connections without blocking
    // Enforce max client limit
    if state.active_clients.len() >= config.max_clients {
        // Reject new connections
        return;
    }
    
    // Non-blocking client management
}

fn compress_screen_data(
    mut state: ResMut<ScreenSharingState>,
    config: Res<ScreenSharingConfig>,
    screen_captures: Option<Res<ScreenCaptures>>,
) {
    let Some(captures) = screen_captures else {
        return;
    };
    
    // Compress screen data using configured quality
    // This integrates with existing screen capture system
}

fn broadcast_to_clients(
    mut state: ResMut<ScreenSharingState>,
    mut events: EventWriter<ScreenSharingEvent>,
) {
    // Broadcast compressed data to all connected clients
    // Handle disconnections gracefully
}

fn screen_sharing_ui(
    mut contexts: EguiContexts,
    state: Res<ScreenSharingState>,
    config: Res<ScreenSharingConfig>,
) {
    let Ok(ctx) = contexts.try_ctx_mut() else {
        return;
    };
    
    egui::Window::new("ð Screen Sharing")
        .default_size([250.0, 150.0])
        .show(ctx, |ui| {
            ui.label(format!("Clients: {}/{}", 
                state.active_clients.len(), 
                config.max_clients
            ));
            
            ui.label(format!("Quality: {:.0}%", config.quality * 100.0));
            
            if ui.button("Stop Sharing").clicked() {
                // Send stop event
            }
        });
}
```

### Integration with main.rs

The complete plugin integration in your main application:

```rust
// src/main.rs - Plugin integration
use crate::plugins::{XRealCorePlugins, XRealScreenSharingPlugin};

fn main() -> Result<()> {
    println!("ð¥½ XREAL Virtual Desktop - Starting up...");
    
    App::new()
        .add_plugins(DefaultPlugins.set(WindowPlugin {
            // ... window configuration
        }))
        
        // Add XREAL core plugin group (handles dependencies)
        .add_plugins(XRealCorePlugins)
        
        // Add optional feature plugins
        .add_plugins(XRealScreenSharingPlugin::default())
        
        // External plugins
        .add_plugins(EguiPlugin::default())
        .add_plugins(FrameTimeDiagnosticsPlugin::default())
        
        .run();
    
    Ok(())
}
```

This plugin system architecture enables modular, maintainable XREAL applications while preserving the performance characteristics essential for AR/VR experiences.

## Bevy State Management Best Practices

### Core Principles for XREAL State Management

State management in XREAL applications requires careful consideration of performance, thread safety, and data flow patterns. This section outlines proven patterns for managing state in high-performance AR applications.

#### Resource vs Component Decision Matrix

```rust
// Use Resources for:
// - Global application state
// - Shared data across many entities
// - Configuration and settings
// - Hardware interface state

#[derive(Resource)]
struct Orientation {
    pub quat: Quat,
}

#[derive(Resource)]
struct DisplayModeState {
    is_3d_enabled: bool,
    pending_change: Option<bool>,
}

// Use Components for:
// - Entity-specific state
// - Renderable objects
// - Behavior modifiers
// - Spatial relationships

#[derive(Component)]
struct HeadCursor {
    size: f32,
    color: Color,
    hit_screen: Option<usize>,
}

#[derive(Component)]
struct VirtualScreen(usize);
```

#### Zero-Allocation State Update Patterns

```rust
// Pre-allocate fixed-size buffers for real-time updates
#[derive(Resource)]
struct JitterMetrics<const BUFFER_SIZE: usize = 1000> {
    // Fixed-size ring buffers - zero heap allocations
    frame_times: [f32; BUFFER_SIZE],
    imu_intervals: [f32; BUFFER_SIZE],
    
    // Ring buffer indices for O(1) operations
    frame_write_idx: usize,
    imu_write_idx: usize,
    
    // Welford's algorithm state for incremental variance
    frame_mean: f32,
    frame_m2: f32,
}

impl<const BUFFER_SIZE: usize> JitterMetrics<BUFFER_SIZE> {
    /// Add measurement using Welford's online algorithm
    /// Provides O(1) variance calculation without storing all values
    #[inline]
    fn add_frame_measurement(&mut self, interval: f32) {
        // Update ring buffer
        self.frame_times[self.frame_write_idx] = interval;
        self.frame_write_idx = (self.frame_write_idx + 1) % BUFFER_SIZE;
        
        // Update Welford's algorithm state
        let delta = interval - self.frame_mean;
        self.frame_mean += delta / self.frame_count as f32;
        self.frame_m2 += delta * (interval - self.frame_mean);
    }
}
```

#### State Synchronization Patterns

```rust
// Pending Change Pattern - Prevents state inconsistencies
#[derive(Resource)]
struct BrightnessState {
    current_level: u8,        // Current brightness 0-7
    pending_change: Option<u8>, // Pending brightness change
}

fn brightness_control_system(
    mut brightness_state: ResMut<BrightnessState>,
    command_channel: Res<CommandChannel>,
) {
    if let Some(new_level) = brightness_state.pending_change {
        // Validate brightness range (0-7)
        let clamped_level = new_level.min(7);
        
        match command_channel.0.try_send(Command::SetBrightness(clamped_level)) {
            Ok(_) => {
                brightness_state.current_level = clamped_level;
                debug!("â Brightness set to level {}", clamped_level);
            }
            Err(e) => {
                error!("â Failed to send brightness command: {}", e);
                // Keep the current state on failure
            }
        }
        brightness_state.pending_change = None;
    }
}
```

#### Input State Management

```rust
// Head-tracked cursor state with dwell time selection
#[derive(Resource)]
struct CursorState {
    pub is_active: bool,
    pub dwell_time: f32,
    pub dwell_threshold: f32,
    pub last_hit_screen: Option<usize>,
    pub last_hit_position: Option<Vec2>,
}

fn update_head_cursor(
    mut cursor_query: Query<(&mut Transform, &mut HeadCursor)>,
    mut cursor_state: ResMut<CursorState>,
    orientation: Res<Orientation>,
    virtual_screens: Query<(&Transform, &VirtualScreen)>,
    time: Res<Time>,
) {
    if !cursor_state.is_active {
        return;
    }

    // Use real head tracking data for cursor positioning
    let head_rotation = orientation.quat;
    let ray_origin = Vec3::ZERO;
    let ray_dir = head_rotation * Vec3::NEG_Z;

    // Update dwell time for gaze selection
    if cursor_state.last_hit_screen == Some(screen_id) {
        cursor_state.dwell_time += time.delta_seconds();
        
        // Change cursor color based on dwell progress
        let progress = cursor_state.dwell_time / cursor_state.dwell_threshold;
        if progress >= 1.0 {
            cursor.color = Color::rgb(1.0, 0.0, 0.0); // Red when ready to select
        } else {
            cursor.color = Color::rgb(progress, 1.0 - progress, 0.0); // Green to yellow
        }
    }
}
```

#### UI State Management Patterns

```rust
// Hierarchical UI state organization
#[derive(Resource, Default)]
struct SettingsPanelState {
    is_open: bool,
    selected_preset: DisplayPreset,
    performance_monitoring: bool,
    advanced_calibration: bool,
}

#[derive(Resource, Default)]
struct TopMenuState {
    is_hovering: bool,
    is_menu_open: bool,
    selected_tab: AppTab,
    hover_timer: f32,
}

// Change detection optimization
fn settings_ui(
    mut contexts: EguiContexts,
    mut settings_state: ResMut<SettingsPanelState>,
    mut display_mode_state: ResMut<DisplayModeState>,
    // Only access resources when needed
    system_status: Res<SystemStatus>,
) {
    // Only update if state has changed
    if !settings_state.is_changed() && !display_mode_state.is_changed() {
        return;
    }
    
    let Ok(ctx) = contexts.try_ctx_mut() else {
        return;
    };
    
    // UI rendering logic
}
```

#### Performance-Conscious State Design

```rust
// System status aggregation - computed once per frame
#[derive(Resource, Default)]
struct SystemStatus {
    current_fps: Option<f32>,
    connection_status: bool,
    capture_active: bool,
}

fn system_status_update_system(
    mut system_status: ResMut<SystemStatus>,
    diagnostics: Res<DiagnosticsStore>,
    glasses_state: Res<GlassesConnectionState>,
    screen_captures: Option<Res<ScreenCaptures>>,
) {
    // Aggregate system status efficiently
    system_status.current_fps = diagnostics
        .get(&FrameTimeDiagnosticsPlugin::FPS)
        .and_then(|fps| fps.average())
        .map(|fps| fps as f32);
    
    system_status.connection_status = match glasses_state.is_connected {
        Some(connected) => connected,
        None => false,
    };
    
    system_status.capture_active = screen_captures.is_some();
}
```

#### State Persistence Patterns

```rust
// Serializable state schema
#[derive(Serialize, Deserialize, Default)]
struct AppState {
    user_preferences: UserPreferences,
    ui_state: UiState,
    calibration_data: CalibrationData,
    performance_settings: PerformanceSettings,
    window_layout: WindowLayout,
    plugin_state: PluginState,
}

// Atomic state persistence
#[derive(Resource)]
struct StatePersistenceManager {
    state_file_path: PathBuf,
    backup_file_path: PathBuf,
    last_save_time: Instant,
    save_interval: Duration,
}

impl StatePersistenceManager {
    /// Save state with atomic file operations
    async fn save_state(&self, state: &AppState) -> Result<()> {
        let temp_path = self.state_file_path.with_extension("tmp");
        
        // Write to temporary file first
        let serialized = serde_json::to_string_pretty(state)?;
        tokio::fs::write(&temp_path, serialized).await?;
        
        // Atomic rename to final location
        tokio::fs::rename(&temp_path, &self.state_file_path).await?;
        
        Ok(())
    }
    
    /// Load state with fallback chain
    async fn load_state(&self) -> Result<AppState> {
        // Try primary state file
        match tokio::fs::read_to_string(&self.state_file_path).await {
            Ok(content) => {
                match serde_json::from_str::<AppState>(&content) {
                    Ok(state) => return Ok(state),
                    Err(e) => warn!("Primary state file corrupted: {}", e),
                }
            }
            Err(e) => warn!("Primary state file not found: {}", e),
        }
        
        // Try backup file
        match tokio::fs::read_to_string(&self.backup_file_path).await {
            Ok(content) => {
                match serde_json::from_str::<AppState>(&content) {
                    Ok(state) => return Ok(state),
                    Err(e) => warn!("Backup state file corrupted: {}", e),
                }
            }
            Err(e) => warn!("Backup state file not found: {}", e),
        }
        
        // Fall back to default state
        Ok(AppState::default())
    }
}
```

#### Error Handling in State Management

```rust
// Graceful error handling in state updates
fn display_mode_system(
    mut display_mode_state: ResMut<DisplayModeState>,
    mut xreal_device: Option<ResMut<XRealDevice>>,
) {
    if let Some(new_mode) = display_mode_state.pending_change {
        if let Some(ref mut device) = xreal_device {
            let xreal_mode = if new_mode { 
                XRealDisplayMode::Stereo 
            } else { 
                XRealDisplayMode::Mirror 
            };
            
            match device.set_display_mode(xreal_mode) {
                Ok(_) => {
                    display_mode_state.is_3d_enabled = new_mode;
                    debug!("â Display mode changed to {}", 
                           if new_mode { "3D Stereo" } else { "2D Mirror" });
                }
                Err(e) => {
                    error!("â Failed to change display mode: {}", e);
                    // Keep the current state, don't update is_3d_enabled
                    // This prevents UI desynchronization
                }
            }
        } else {
            debug!("No XREAL device available for display mode change");
        }
        
        // Clear pending change regardless of success/failure
        display_mode_state.pending_change = None;
    }
}
```

#### Channel-Based State Communication

```rust
// Efficient channel communication between async and sync systems
#[derive(Resource)]
struct CommandChannel(Sender<Command>);

#[derive(Resource)]
struct DataChannel(Receiver<Data>);

#[derive(Resource)]
struct ImuChannels {
    tx_data: Sender<Data>,
    rx_command: Receiver<Command>,
}

fn update_from_data_channel(
    rx: ResMut<DataChannel>,
    mut orientation: ResMut<Orientation>,
    mut cal_state: ResMut<CalibrationState>,
) {
    // Non-blocking channel reads
    while let Ok(data) = rx.0.try_recv() {
        match data {
            Data::Orientation(q) => orientation.quat = q,
            Data::CalState(s) => *cal_state = s,
        }
    }
}
```

#### System Sets for State Ordering

```rust
// Organize state updates with system sets
#[derive(SystemSet, Debug, Hash, PartialEq, Eq, Clone)]
enum StateSystemSets {
    Input,        // Process input events
    Processing,   // Update state based on input
    Hardware,     // Apply state to hardware
    UI,           // Update UI based on state
    Persistence,  // Save state changes
}

// Configure system ordering
app.configure_sets(FixedUpdate, (
    StateSystemSets::Input,
    StateSystemSets::Processing,
    StateSystemSets::Hardware,
    StateSystemSets::UI,
    StateSystemSets::Persistence,
).chain())
.add_systems(FixedUpdate, (
    handle_input.in_set(StateSystemSets::Input),
    update_head_cursor.in_set(StateSystemSets::Processing),
    display_mode_system.in_set(StateSystemSets::Hardware),
    settings_ui.in_set(StateSystemSets::UI),
    save_state_periodically.in_set(StateSystemSets::Persistence),
));
```

### Advanced State Management Patterns

#### State Machines for Complex Workflows

```rust
// Calibration state machine
#[derive(Copy, Clone, Resource)]
pub enum CalibrationState {
    Idle,
    Calibrating { 
        start_time: Instant, 
        gyro_count: usize, 
        accel_count: usize, 
        mag_count: usize,
        // Fixed-size arrays for zero allocation
        gyro_samples: [[f32; 3]; 5000], 
        accel_samples: [[f32; 3]; 5000], 
        mag_samples: [[f32; 3]; 5000] 
    },
    Calibrated { 
        gyro_bias: [f32; 3], 
        accel_bias: [f32; 3], 
        mag_bias: [f32; 3] 
    },
}

fn calibration_state_machine(
    mut cal_state: ResMut<CalibrationState>,
    time: Res<Time>,
    command_channel: Res<CommandChannel>,
) {
    match *cal_state {
        CalibrationState::Idle => {
            // Wait for calibration command
        }
        CalibrationState::Calibrating { start_time, .. } => {
            if start_time.elapsed() > Duration::from_secs(5) {
                // Transition to calibrated state
                let biases = calculate_biases(&cal_state);
                *cal_state = CalibrationState::Calibrated {
                    gyro_bias: biases.gyro,
                    accel_bias: biases.accel,
                    mag_bias: biases.mag,
                };
            }
        }
        CalibrationState::Calibrated { .. } => {
            // Calibration complete, normal operation
        }
    }
}
```

#### Reactive State Updates

```rust
// Reactive updates using change detection
fn reactive_cursor_material_update(
    cursor_query: Query<(&Handle<StandardMaterial>, &HeadCursor), Changed<HeadCursor>>,
    mut materials: ResMut<Assets<StandardMaterial>>,
) {
    // Only update materials when HeadCursor changes
    for (material_handle, cursor) in cursor_query.iter() {
        if let Some(material) = materials.get_mut(material_handle) {
            material.base_color = cursor.color;
            material.emissive = cursor.color * 0.3;
        }
    }
}
```

These patterns ensure that XREAL applications maintain high performance while providing robust state management capabilities essential for AR/VR applications.

## Performance & Jitter Elimination

### Async-First Design Principles

#### Eliminate Blocking Operations
- **No spawn_blocking**: Use AsyncComputeTaskPool exclusively
- **No block_on** (except for polling): All operations must be truly async
- **No synchronous file I/O**: Convert all fs operations to async

#### Optimal Threading Model
```rust
// Main thread: Bevy systems and rendering
// AsyncComputeTaskPool: IMU polling, screen capture, system calls
// Communication: Lock-free channels for data flow
```

### Sensor Fusion Optimization

#### IMU Processing Pipeline
```rust
use imu_fusion::{Fusion, FusionAhrsSettings, FusionVector};

async fn process_imu_data() -> Result<Quat> {
    let ahrs_settings = FusionAhrsSettings::new();
    let mut fusion = Fusion::new(1000, ahrs_settings); // 1000Hz sample rate
    
    // Process sensor data with bias compensation
    let gyro_vec = FusionVector { 
        x: gyro_x - gyro_bias[0], 
        y: gyro_y - gyro_bias[1], 
        z: gyro_z - gyro_bias[2] 
    };
    
    fusion.update(gyro_vec, accel_vec, mag_vec, dt);
    let quat = fusion.quaternion();
    
    Ok(Quat::from_xyzw(quat.x, quat.y, quat.z, quat.w))
}
```

#### Quaternion Smoothing
```rust
use quaternion_core::slerp;

// Apply smoothing to reduce jitter
let alpha = 0.05f32; // Smoothing factor
let smooth_q = slerp(previous_quat, current_quat, alpha);
```

#### Roll Lock Implementation
```rust
fn apply_roll_lock(quat: Quat) -> Quat {
    let euler = quat.to_euler(EulerRot::YXZ);
    // Lock roll to 0 for text stability
    Quat::from_euler(EulerRot::YXZ, euler.0, euler.1, 0.0)
}
```

### Screen Capture Optimization

#### Zero-Allocation Patterns
```rust
pub struct ScreenCaptures {
    // Pre-allocated buffer pool
    rgba_buffer: Vec<u8>,
    buffer_capacity: usize,
}

impl ScreenCaptures {
    fn new() -> Result<Self> {
        // Pre-allocate for 4K RGBA to avoid hot-path allocations
        const MAX_BUFFER_SIZE: usize = 3840 * 2160 * 4;
        let rgba_buffer = Vec::with_capacity(MAX_BUFFER_SIZE);
        
        Ok(Self {
            rgba_buffer,
            buffer_capacity: MAX_BUFFER_SIZE,
        })
    }
}
```

#### Adaptive Frame Rate Detection
```rust
fn detect_optimal_framerate() -> u32 {
    // Priority: 120Hz (XREAL 2 Pro), 90Hz (XREAL 2), 72Hz (Air), 60Hz (fallback)
    if let Ok(output) = std::process::Command::new("system_profiler")
        .args(&["SPDisplaysDataType"])
        .output() 
    {
        let display_info = String::from_utf8_lossy(&output.stdout);
        
        if display_info.contains("120") {
            return 120; // XREAL 2 Pro
        } else if display_info.contains("90") {
            return 90;  // XREAL 2
        } else if display_info.contains("72") {
            return 72;  // XREAL Air series
        }
    }
    
    60 // Safe fallback
}
```

## Implementation Details

### IMU Calibration System

#### Calibration Process
```rust
#[derive(Copy, Clone, Resource)]
pub enum CalibrationState {
    Idle,
    Calibrating { 
        start_time: Instant, 
        gyro_count: usize, 
        accel_count: usize, 
        mag_count: usize, 
        gyro_samples: [[f32; 3]; 5000], 
        accel_samples: [[f32; 3]; 5000], 
        mag_samples: [[f32; 3]; 5000] 
    },
    Calibrated { 
        gyro_bias: [f32; 3], 
        accel_bias: [f32; 3], 
        mag_bias: [f32; 3] 
    },
}
```

#### Bias Calculation
```rust
// Collect 5000 samples over 5 seconds
if start_time.elapsed() > Duration::from_secs(5) {
    let gyro_bias_x = gyro_samples[0..gyro_count].iter()
        .map(|s| s[0]).sum::<f32>() / gyro_count as f32;
    
    // Compensate for gravity in Z-axis
    let accel_bias_z = accel_samples[0..accel_count].iter()
        .map(|s| s[2]).sum::<f32>() / accel_count as f32 - 9.81;
    
    cal_state = CalibrationState::Calibrated { gyro_bias, accel_bias, mag_bias };
}
```

### Error Handling Patterns

#### Robust Error Propagation
```rust
use anyhow::Result;

// All fallible operations use anyhow::Result
async fn poll_imu() -> Result<()> {
    let glasses = init_glasses()?;
    
    loop {
        let events = poll_events(&glasses).await?;
        
        for event in events {
            match event {
                GlassesEvent::AccGyro { .. } => {
                    // Process with error handling
                    if tx_data.send(orientation).await.is_err() {
                        return Err(anyhow::anyhow!("Failed to send orientation"));
                    }
                }
                _ => {}
            }
        }
    }
}
```

#### Channel Failure Management
```rust
// Bounded channels prevent memory accumulation
let (tx, rx) = crossbeam_channel::bounded::<Data>(1);

// Handle channel failures gracefully
if let Err(_) = tx.try_send(data) {
    warn!("Channel full, dropping frame");
    // Continue processing rather than failing
}
```

## Development Best Practices

### Async Programming Guidelines

#### CommandQueue Pattern
```rust
async fn async_task() -> CommandQueue {
    let mut command_queue = CommandQueue::default();
    
    // Perform async work
    let result = perform_async_operation().await;
    
    // Use CommandQueue for deferred world updates
    command_queue.push(move |world: &mut World| {
        // Apply results to ECS world
        world.resource_mut::<SomeResource>().update(result);
    });
    
    command_queue
}
```

#### Resource Lifecycle Management
```rust
impl Drop for ScreenCaptures {
    fn drop(&mut self) {
        if let Some(ref mut capturer) = self.capturer {
            capturer.stop_capture();
        }
    }
}
```

### Testing Strategies

#### Unit Testing Async Functions
```rust
#[tokio::test]
async fn test_imu_processing() {
    let (tx, rx) = crossbeam_channel::bounded(10);
    
    // Test async IMU processing
    let result = process_test_imu_data(tx).await;
    
    assert!(result.is_ok());
    assert!(rx.try_recv().is_ok());
}
```

#### Integration Testing
```rust
#[test]
fn test_bevy_integration() {
    let mut app = App::new();
    app.add_plugins(MinimalPlugins)
       .insert_resource(Orientation::default())
       .add_systems(Update, update_camera_from_orientation);
    
    app.update();
    
    // Verify system integration
}
```

### Performance Monitoring

#### FPS Diagnostics
```rust
use bevy::diagnostic::{DiagnosticsStore, FrameTimeDiagnosticsPlugin};

fn log_fps(diagnostics: Res<DiagnosticsStore>) {
    if let Some(fps) = diagnostics.get(&FrameTimeDiagnosticsPlugin::FPS) {
        if let Some(value) = fps.average() {
            trace!("FPS: {}", value);
        }
    }
}
```

#### Fixed Timestep Scheduling
```rust
// 1ms fixed timestep for consistent updates
app.insert_resource(Time::<Fixed>::from_duration(Duration::from_millis(1)))
   .add_systems(FixedUpdate, (update_orientation, update_camera));
```

## Common Issues and Solutions

### Thread Safety
**Issue**: `std::sync::mpsc` channels are `!Sync`
**Solution**: Use `crossbeam_channel` for Bevy resource compatibility

### Jitter Reduction
**Issue**: Sensor data jitter affecting display stability
**Solution**: Apply quaternion smoothing with slerp interpolation

### Performance Bottlenecks
**Issue**: Blocking operations causing frame drops
**Solution**: Convert all operations to use AsyncComputeTaskPool

### Memory Management
**Issue**: Hot-path allocations during screen capture
**Solution**: Pre-allocate buffer pools for maximum expected data sizes

## WGPU Surface Access and Custom Rendering

### Accessing WGPU Resources in Bevy

Bevy provides direct access to WGPU resources through its render pipeline architecture, enabling custom rendering alongside egui UI components.

#### Core WGPU Resources
```rust
// Access render resources in render world systems
fn custom_render_system(
    render_device: Res<RenderDevice>,      // Main GPU device
    render_queue: Res<RenderQueue>,        // Command queue
    render_adapter: Res<RenderAdapter>,    // Physical GPU handle
) {
    // Create GPU resources directly
    let buffer = render_device.create_buffer(&BufferDescriptor {
        label: Some("Custom Buffer"),
        size: 1024,
        usage: BufferUsages::UNIFORM | BufferUsages::COPY_DST,
        mapped_at_creation: false,
    });
}
```

#### Render World vs Main World Pattern
```rust
// Extract phase: Copy data from main world to render world
fn extract_custom_data(
    mut commands: Commands,
    main_world_query: Extract<Query<&CustomComponent>>,
) {
    for component in main_world_query.iter() {
        commands.spawn(ExtractedCustomData::from(component));
    }
}

// Prepare phase: Set up GPU resources
fn prepare_custom_resources(
    render_device: Res<RenderDevice>,
    render_queue: Res<RenderQueue>,
    mut custom_resources: ResMut<CustomRenderResources>,
) {
    // Update uniform buffers
    render_queue.write_buffer(&custom_resources.uniform_buffer, 0, &uniform_data);
}
```

### Bevy-egui Integration for Custom Rendering

#### Custom 3D Rendering within egui
```rust
// Store custom render resources in egui's paint callback system
render_state
    .egui_rpass
    .write()
    .paint_callback_resources
    .insert(CustomRenderResources {
        pipeline,
        bind_group,
        uniform_buffer,
    });

// Create paint callback for custom rendering
let render_callback = egui_wgpu::CallbackFn::new()
    .prepare(move |device, queue, paint_callback_resources| {
        // Access WGPU device and queue directly
        let resources: &CustomRenderResources = 
            paint_callback_resources.get().unwrap();
        
        // Update GPU resources
        queue.write_buffer(&resources.uniform_buffer, 0, &updated_data);
    })
    .paint(move |_info, render_pass, paint_callback_resources| {
        // Issue draw commands using WGPU render pass
        let resources: &CustomRenderResources = 
            paint_callback_resources.get().unwrap();
        
        render_pass.set_pipeline(&resources.pipeline);
        render_pass.set_bind_group(0, &resources.bind_group, &[]);
        render_pass.draw(0..3, 0..1);
    });

// Use in egui UI
ui.painter().add(egui_wgpu::Callback::new_paint_callback(
    rect, render_callback
));
```

### Custom Render Graph Nodes

#### Implementing ViewNode for Surface Access
```rust
impl ViewNode for XRealCustomRenderNode {
    type ViewQuery = (&'static ExtractedCamera, &'static ViewTarget);

    fn run(
        &self,
        _graph: &mut RenderGraphContext,
        render_context: &mut RenderContext,
        (camera, view_target): QueryItem<Self::ViewQuery>,
        world: &World,
    ) -> Result<(), NodeRunError> {
        // Access the main surface texture
        let surface_texture = view_target.main_texture_view();
        
        // Create command encoder for custom rendering
        let mut encoder = render_context
            .render_device()
            .create_command_encoder(&CommandEncoderDescriptor::default());
        
        {
            let mut render_pass = encoder.begin_render_pass(&RenderPassDescriptor {
                label: Some("XREAL Custom Render Pass"),
                color_attachments: &[Some(RenderPassColorAttachment {
                    view: surface_texture,
                    resolve_target: None,
                    ops: Operations {
                        load: LoadOp::Load, // Preserve existing content
                        store: true,
                    },
                })],
                depth_stencil_attachment: None,
            });
            
            // Custom rendering commands
            // This renders on top of or alongside egui content
        }
        
        // Submit commands to GPU
        render_context.add_command_buffer(encoder.finish());
        
        Ok(())
    }
}
```

### Surface and Texture Sharing Strategies

#### Render-to-Texture for XREAL Stereo Display
```rust
#[derive(Resource)]
struct XRealStereoTextures {
    left_eye_texture: Texture,
    right_eye_texture: Texture,
    left_eye_view: TextureView,
    right_eye_view: TextureView,
}

impl FromWorld for XRealStereoTextures {
    fn from_world(world: &mut World) -> Self {
        let render_device = world.resource::<RenderDevice>();
        
        let texture_descriptor = TextureDescriptor {
            label: Some("XREAL Eye Texture"),
            size: Extent3d {
                width: 1920, // XREAL resolution
                height: 1080,
                depth_or_array_layers: 1,
            },
            mip_level_count: 1,
            sample_count: 1,
            dimension: TextureDimension::D2,
            format: TextureFormat::Rgba8UnormSrgb,
            usage: TextureUsages::RENDER_ATTACHMENT | TextureUsages::TEXTURE_BINDING,
            view_formats: &[],
        };
        
        let left_eye_texture = render_device.create_texture(&texture_descriptor);
        let right_eye_texture = render_device.create_texture(&texture_descriptor);
        
        Self {
            left_eye_view: left_eye_texture.create_view(&TextureViewDescriptor::default()),
            right_eye_view: right_eye_texture.create_view(&TextureViewDescriptor::default()),
            left_eye_texture,
            right_eye_texture,
        }
    }
}
```

#### Displaying Custom Textures in egui
```rust
fn display_stereo_view_in_egui(
    mut contexts: EguiContexts,
    stereo_textures: Res<XRealStereoTextures>,
    mut egui_user_textures: ResMut<bevy_egui::EguiUserTextures>,
) {
    let ctx = contexts.ctx_mut();
    
    // Register custom textures with egui
    let left_texture_id = egui_user_textures.add_texture(&stereo_textures.left_eye_texture);
    let right_texture_id = egui_user_textures.add_texture(&stereo_textures.right_eye_texture);
    
    egui::Window::new("XREAL Stereo View").show(ctx, |ui| {
        ui.horizontal(|ui| {
            ui.label("Left Eye:");
            ui.image(left_texture_id, [400.0, 300.0]);
            
            ui.label("Right Eye:");
            ui.image(right_texture_id, [400.0, 300.0]);
        });
    });
}
```

### Custom Render Pipeline Integration

#### Creating XREAL-Specific Render Pipeline
```rust
#[derive(Resource)]
struct XRealRenderPipeline {
    stereo_pipeline_id: CachedRenderPipelineId,
    distortion_pipeline_id: CachedRenderPipelineId,
}

impl FromWorld for XRealRenderPipeline {
    fn from_world(world: &mut World) -> Self {
        let asset_server = world.resource::<AssetServer>();
        let mut pipeline_cache = world.resource_mut::<PipelineCache>();
        
        // Stereo rendering pipeline for side-by-side display
        let stereo_shader = asset_server.load("shaders/xreal_stereo.wgsl");
        let stereo_pipeline_id = pipeline_cache.queue_render_pipeline(
            RenderPipelineDescriptor {
                label: Some("XREAL Stereo Pipeline"),
                layout: vec![],
                vertex: VertexState {
                    shader: stereo_shader.clone(),
                    shader_defs: vec![],
                    entry_point: "vs_main".into(),
                    buffers: vec![],
                },
                fragment: Some(FragmentState {
                    shader: stereo_shader,
                    shader_defs: vec![],
                    entry_point: "fs_main".into(),
                    targets: vec![Some(ColorTargetState {
                        format: TextureFormat::Rgba8UnormSrgb,
                        blend: Some(BlendState::ALPHA_BLENDING),
                        write_mask: ColorWrites::ALL,
                    })],
                }),
                primitive: PrimitiveState::default(),
                depth_stencil: None,
                multisample: MultisampleState::default(),
                push_constant_ranges: vec![],
            }
        );
        
        Self {
            stereo_pipeline_id,
            distortion_pipeline_id: stereo_pipeline_id, // Placeholder
        }
    }
}
```

### Performance Considerations for XREAL

#### Efficient Resource Management
```rust
fn update_xreal_stereo_uniforms(
    render_device: Res<RenderDevice>,
    render_queue: Res<RenderQueue>,
    orientation: Res<Orientation>,
    mut stereo_uniforms: ResMut<XRealStereoUniforms>,
) {
    // Calculate stereo projection matrices based on head orientation
    let view_matrix = Mat4::from_quat(orientation.quat.inverse());
    let left_projection = calculate_left_eye_projection();
    let right_projection = calculate_right_eye_projection();
    
    // Update uniform buffer efficiently
    let uniform_data = XRealUniformData {
        left_view_proj: left_projection * view_matrix,
        right_view_proj: right_projection * view_matrix,
        ipd_offset: 0.063, // 63mm interpupillary distance
    };
    
    render_queue.write_buffer(
        &stereo_uniforms.buffer,
        0,
        bytemuck::cast_slice(&[uniform_data]),
    );
}
```

#### Memory Management for High-Frequency Updates
```rust
// Pre-allocate GPU resources to avoid runtime allocation
#[derive(Resource)]
struct XRealGPUResources {
    uniform_buffer: Buffer,
    bind_group: BindGroup,
    vertex_buffer: Buffer,
}

impl XRealGPUResources {
    fn new(render_device: &RenderDevice, layout: &BindGroupLayout) -> Self {
        let uniform_buffer = render_device.create_buffer(&BufferDescriptor {
            label: Some("XREAL Uniform Buffer"),
            size: std::mem::size_of::<XRealUniformData>() as u64,
            usage: BufferUsages::UNIFORM | BufferUsages::COPY_DST,
            mapped_at_creation: false,
        });
        
        let bind_group = render_device.create_bind_group(&BindGroupDescriptor {
            label: Some("XREAL Bind Group"),
            layout,
            entries: &[BindGroupEntry {
                binding: 0,
                resource: uniform_buffer.as_entire_binding(),
            }],
        });
        
        Self {
            uniform_buffer,
            bind_group,
            vertex_buffer: Self::create_quad_vertices(render_device),
        }
    }
}
```

### Integration with XREAL Head Tracking

#### Real-time Camera Updates
```rust
fn update_xreal_camera_from_imu(
    orientation: Res<Orientation>,
    mut camera_query: Query<&mut Transform, With<XRealCamera>>,
) {
    for mut transform in camera_query.iter_mut() {
        // Apply head tracking orientation to camera
        transform.rotation = orientation.quat;
        
        // Apply position tracking if available
        // (Future: integrate with SLAM or external tracking)
    }
}
```

This integration enables powerful custom rendering capabilities within the XREAL ecosystem while maintaining compatibility with egui UI components and Bevy's efficient render pipeline.

## Future Considerations

### Hardware Evolution
- Support for newer XREAL models with higher refresh rates
- Integration with upcoming AR glasses from other manufacturers
- Adaptation to new USB-C protocol versions

### Software Optimization
- GPU-accelerated sensor fusion using compute shaders
- Advanced prediction algorithms for motion compensation
- Real-time performance profiling and adjustment
- WGPU-based stereo rendering optimizations

### Platform Expansion
- Windows and Linux compatibility layers
- Mobile platform integration (iOS/Android)
- VR headset protocol adaptation
- WebGPU support for browser-based XREAL applications

This guide provides the foundation for building jitter-free, high-performance XREAL AR applications using modern Rust async patterns, Bevy ECS architecture, and direct WGPU surface access for advanced rendering capabilities.

# AR-Drivers Comprehensive Feature Reference

## Core AR Glasses Support Features

### Hardware Device Support
- **`nreal`**: XREAL Air, Air 2, Air 2 Pro (formerly Nreal) - Primary target hardware with full DisplayPort support
- **`rokid`**: Rokid Air, Max - Alternative AR glasses with similar capabilities
- **`mad_gaze`**: Mad Gaze Glow - Compact AR glasses with basic display functionality
- **`grawoow`**: Grawoow G530 - Gaming-focused AR glasses with enhanced refresh rates

### Communication Protocol Features
- **`rusb`**: USB communication layer for direct device access and control
- **`hidapi`**: Human Interface Device API for sensor data and device commands
- **`serialport`**: Serial communication protocol for legacy device support
- **`libusb`**: Low-level USB access for performance-critical operations
- **`hotplug`**: Dynamic device detection and connection management
- **`udev`**: Linux device management and enumeration

### Advanced Hardware Features
- **`camera`**: Built-in camera support for passthrough and computer vision
- **`sensors`**: Extended sensor data including proximity, ambient light, and temperature
- **`calibration`**: Display calibration and color management
- **`passthrough`**: Camera feed integration for mixed reality experiences
- **`tracking`**: Enhanced head tracking with 6DOF support
- **`stereo`**: Stereo rendering pipeline with IPD adjustment

### Performance Optimization Features
- **`async`**: Asynchronous I/O operations for non-blocking device communication
- **`zerocopy`**: Zero-copy buffer operations for minimal latency
- **`simd`**: SIMD optimizations for sensor data processing
- **`benchmark`**: Performance benchmarking and profiling tools
- **`profiling`**: Runtime performance analysis and optimization

### Platform Support Features
- **`android`**: Android platform integration with native activity support
- **`ios`**: iOS platform support (future roadmap)
- **`windows`**: Windows platform with DirectX integration
- **`linux`**: Linux platform with X11/Wayland support
- **`macos`**: macOS platform with Metal rendering support

## Extended AR Glasses Ecosystem

### Future Hardware Support
- **`apple_vision`**: Apple Vision Pro integration (when available)
- **`meta_quest`**: Meta Quest display-only mode support
- **`varjo`**: Varjo Aero and other high-end AR headsets
- **`pico`**: Pico 4 Enterprise and consumer headsets
- **`vive`**: HTC Vive AR glasses series
- **`magic_leap`**: Magic Leap 2 and future devices
- **`hololens`**: Microsoft HoloLens enterprise integration
- **`rayneo`**: TCL RayNeo X2 and Air series
- **`vuzix`**: Vuzix Blade and M-series smart glasses
- **`epson`**: Epson Moverio BT series
- **`lenovo`**: Lenovo ThinkReality A3 and VRX
- **`oppo`**: Oppo Air Glass and future models
- **`xiaomi`**: Xiaomi Wireless AR Glass Discovery Edition
- **`huawei`**: Huawei VR Glass 6DOF and AR Glass
- **`lg`**: LG UltraGear AR glasses
- **`asus`**: ASUS mixed reality headsets
- **`acer`**: Acer Windows Mixed Reality devices
- **`hp`**: HP Reverb G2 Omnicept and AR variants
- **`valve`**: Valve Index display-only mode
- **`pimax`**: Pimax Crystal and high-resolution headsets
- **`bigscreen`**: Bigscreen Beyond lightweight VR
- **`simula`**: Simula One Linux-native AR computer
- **`north`**: North Focals legacy support
- **`google`**: Google Glass Enterprise Edition
- **`microsoft`**: Microsoft Mixed Reality platform
- **`qualcomm`**: Qualcomm Snapdragon AR reference designs

### Development and Testing Features
- **`debug`**: Debug logging and diagnostic information
- **`trace`**: Detailed execution tracing and performance monitoring
- **`mock`**: Mock device implementations for testing without hardware
- **`simulator`**: Device behavior simulation for development
- **`telemetry`**: Usage telemetry and analytics collection
- **`diagnostics`**: Hardware diagnostics and health monitoring

## Advanced Functionality Features

### Sensor and Tracking
- **`eye_tracking`**: Eye tracking integration for gaze-based interaction
- **`hand_tracking`**: Hand tracking and gesture recognition
- **`facial_tracking`**: Facial expression tracking and avatar control
- **`voice_commands`**: Voice command integration and speech recognition
- **`gesture_recognition`**: Advanced gesture recognition and control
- **`spatial_audio`**: 3D spatial audio processing and rendering
- **`haptic_feedback`**: Haptic feedback device integration
- **`slam`**: Simultaneous Localization and Mapping
- **`occlusion`**: Real-world occlusion handling
- **`lighting_estimation`**: Environmental lighting estimation
- **`depth_sensing`**: Depth sensor integration and processing
- **`world_tracking`**: World-scale tracking and anchoring
- **`persistence`**: Persistent virtual object anchoring

### Connectivity and Communication
- **`wireless`**: Wireless connectivity management
- **`bluetooth`**: Bluetooth device integration
- **`wifi_direct`**: WiFi Direct peer-to-peer communication
- **`5g`**: 5G connectivity optimization
- **`edge_computing`**: Edge computing integration
- **`cloud_rendering`**: Cloud-based rendering and streaming
- **`streaming`**: Real-time video streaming capabilities
- **`recording`**: Video recording and capture
- **`screenshot`**: Screenshot and image capture
- **`screen_sharing`**: Screen sharing and collaboration
- **`remote_desktop`**: Remote desktop integration
- **`cloud_sync`**: Cloud synchronization and backup

### AI and Machine Learning
- **`ai_acceleration`**: AI processing acceleration
- **`neural_processing`**: Neural processing unit integration
- **`computer_vision`**: Computer vision processing pipeline
- **`machine_learning`**: Machine learning model integration
- **`deep_learning`**: Deep learning inference
- **`neural_networks`**: Neural network processing
- **`reinforcement_learning`**: Reinforcement learning integration
- **`computer_vision_ml`**: ML-powered computer vision
- **`nlp`**: Natural language processing
- **`sentiment_analysis`**: Sentiment analysis and emotion detection
- **`language_translation`**: Real-time language translation
- **`object_detection`**: Object detection and recognition
- **`face_recognition`**: Face recognition and identification
- **`gesture_ml`**: ML-based gesture recognition
- **`pose_estimation`**: Human pose estimation
- **`activity_recognition`**: Activity and behavior recognition
- **`behavior_analysis`**: User behavior analysis
- **`predictive_analytics`**: Predictive analytics and forecasting
- **`anomaly_detection`**: Anomaly detection and alerting
- **`recommendation_engine`**: Recommendation system integration
- **`personalization`**: Personalized user experiences
- **`adaptive_ui`**: Adaptive user interface systems
- **`context_awareness`**: Context-aware computing

### Computing Paradigms
- **`ambient_computing`**: Ambient and ubiquitous computing
- **`ubiquitous_computing`**: Ubiquitous computing integration
- **`pervasive_computing`**: Pervasive computing systems
- **`fog_computing`**: Fog computing edge processing
- **`mec`**: Multi-access edge computing
- **`quantum_computing`**: Quantum computing readiness
- **`blockchain`**: Blockchain integration and smart contracts
- **`cryptocurrency`**: Cryptocurrency wallet integration
- **`nft`**: NFT display and marketplace integration
- **`defi`**: Decentralized finance integration
- **`web3`**: Web3 and decentralized web support
- **`ipfs`**: InterPlanetary File System integration
- **`distributed_storage`**: Distributed storage systems
- **`p2p`**: Peer-to-peer networking
- **`mesh_networking`**: Mesh networking protocols

### Media and Content
- **`multiplayer`**: Multi-user and collaborative experiences
- **`backup`**: Settings and data backup
- **`analytics`**: Usage analytics and insights
- **`crash_reporting`**: Crash reporting and error analysis
- **`auto_update`**: Automatic software updates
- **`plugin_system`**: Plugin architecture and extensibility
- **`scripting`**: Scripting engine integration
- **`web_engine`**: Web engine and browser integration
- **`media_playback`**: Media playback optimization
- **`game_engine`**: Game engine integration
- **`productivity`**: Productivity application integration

### Accessibility and Internationalization
- **`accessibility`**: Accessibility features and compliance
- **`internationalization`**: Internationalization support
- **`localization`**: Localization and translation
- **`speech_recognition`**: Speech recognition integration
- **`text_to_speech`**: Text-to-speech synthesis
- **`natural_language`**: Natural language processing

### Security and Privacy
- **`security`**: Security features and protocols
- **`encryption`**: Data encryption and secure communication
- **`authentication`**: User authentication systems
- **`authorization`**: Permission and access control
- **`privacy`**: Privacy protection and data handling
- **`parental_controls`**: Parental control systems
- **`biometric_auth`**: Biometric authentication
- **`smart_cards`**: Smart card integration
- **`hardware_security`**: Hardware security modules
- **`trusted_platform`**: Trusted platform module support
- **`secure_boot`**: Secure boot and verified startup
- **`code_signing`**: Code signing and verification
- **`sandboxing`**: Application sandboxing
- **`containerization`**: Container security and isolation

### Enterprise and Business
- **`enterprise`**: Enterprise features and management
- **`mdm`**: Mobile device management
- **`kiosk_mode`**: Kiosk and single-app mode
- **`multi_tenant`**: Multi-tenant architecture
- **`compliance`**: Regulatory compliance frameworks
- **`audit_logging`**: Audit logging and compliance
- **`data_retention`**: Data retention policies
- **`gdpr`**: GDPR compliance features
- **`hipaa`**: HIPAA compliance for healthcare
- **`sox`**: Sarbanes-Oxley compliance
- **`oauth`**: OAuth authentication integration
- **`saml`**: SAML identity federation
- **`ldap`**: LDAP directory integration
- **`active_directory`**: Active Directory integration
- **`single_sign_on`**: Single sign-on systems
- **`multi_factor_auth`**: Multi-factor authentication

### Development and Integration
- **`custom_hardware`**: Custom hardware integration
- **`oem_support`**: OEM customization support
- **`white_label`**: White-label solution support
- **`sdk`**: Software development kit
- **`api`**: REST API integration
- **`webhooks`**: Webhook integration and callbacks
- **`ci_cd`**: Continuous integration and deployment
- **`devops`**: DevOps tools and automation
- **`monitoring`**: System monitoring and alerting
- **`logging`**: Centralized logging systems
- **`metrics`**: Metrics collection and analysis
- **`alerting`**: Alerting and notification systems
- **`health_checks`**: Health monitoring and checks
- **`load_balancing`**: Load balancing and distribution
- **`auto_scaling`**: Auto-scaling capabilities
- **`disaster_recovery`**: Disaster recovery systems
- **`high_availability`**: High availability architecture
- **`fault_tolerance`**: Fault tolerance and resilience
- **`circuit_breaker`**: Circuit breaker patterns
- **`rate_limiting`**: Rate limiting and throttling
- **`throttling`**: Request throttling
- **`caching`**: Caching strategies and systems
- **`cdn`**: Content delivery network integration

### Database and Storage
- **`database`**: Database integration and management
- **`nosql`**: NoSQL database support
- **`sql`**: SQL database integration
- **`graph_database`**: Graph database support
- **`time_series`**: Time series database integration
- **`search_engine`**: Search engine integration
- **`message_queue`**: Message queue systems
- **`event_streaming`**: Event streaming platforms
- **`real_time`**: Real-time communication systems
- **`websockets`**: WebSocket communication
- **`grpc`**: gRPC service integration
- **`graphql`**: GraphQL API support
- **`rest`**: REST API integration
- **`soap`**: SOAP protocol support
- **`json_rpc`**: JSON-RPC protocol
- **`xml_rpc`**: XML-RPC protocol
- **`protobuf`**: Protocol Buffers serialization
- **`avro`**: Apache Avro serialization
- **`thrift`**: Apache Thrift serialization
- **`messagepack`**: MessagePack serialization
- **`cbor`**: CBOR encoding support
- **`bson`**: BSON encoding support
- **`yaml`**: YAML configuration support
- **`toml`**: TOML configuration support
- **`ini`**: INI file configuration
- **`csv`**: CSV data processing
- **`excel`**: Excel file integration
- **`pdf`**: PDF processing and generation
- **`image_processing`**: Image processing and manipulation
- **`video_processing`**: Video processing and encoding
- **`audio_processing`**: Audio processing and effects

### Cloud and Infrastructure
- **`aws`**: Amazon Web Services integration
- **`azure`**: Microsoft Azure integration
- **`gcp`**: Google Cloud Platform integration
- **`alibaba_cloud`**: Alibaba Cloud integration
- **`tencent_cloud`**: Tencent Cloud integration
- **`huawei_cloud`**: Huawei Cloud integration
- **`oracle_cloud`**: Oracle Cloud integration
- **`ibm_cloud`**: IBM Cloud integration
- **`digitalocean`**: DigitalOcean integration
- **`linode`**: Linode integration
- **`vultr`**: Vultr integration
- **`hetzner`**: Hetzner integration
- **`scaleway`**: Scaleway integration
- **`cloudflare`**: Cloudflare integration
- **`fastly`**: Fastly CDN integration
- **`keycdn`**: KeyCDN integration
- **`bunnycdn`**: BunnyCDN integration
- **`stackpath`**: StackPath integration
- **`maxcdn`**: MaxCDN integration
- **`heroku`**: Heroku deployment
- **`vercel`**: Vercel deployment
- **`netlify`**: Netlify deployment
- **`firebase`**: Firebase integration
- **`supabase`**: Supabase integration
- **`planetscale`**: PlanetScale database
- **`neon`**: Neon database integration
- **`cockroachdb`**: CockroachDB integration
- **`mongodb_atlas`**: MongoDB Atlas integration
- **`redis_cloud`**: Redis Cloud integration
- **`elastic_cloud`**: Elastic Cloud integration
- **`confluent`**: Confluent Kafka integration
- **`snowflake`**: Snowflake data warehouse
- **`databricks`**: Databricks integration

### Analytics and Monitoring
- **`datadog`**: Datadog monitoring integration
- **`newrelic`**: New Relic monitoring
- **`splunk`**: Splunk analytics platform
- **`elastic`**: Elastic Stack integration
- **`grafana`**: Grafana visualization
- **`prometheus`**: Prometheus metrics
- **`jaeger`**: Jaeger tracing
- **`zipkin`**: Zipkin tracing
- **`opentelemetry`**: OpenTelemetry integration
- **`sentry`**: Sentry error tracking
- **`bugsnag`**: Bugsnag error monitoring
- **`rollbar`**: Rollbar error tracking
- **`honeybadger`**: Honeybadger monitoring
- **`airbrake`**: Airbrake error tracking
- **`raygun`**: Raygun error monitoring
- **`logrocket`**: LogRocket session replay
- **`fullstory`**: FullStory user analytics
- **`hotjar`**: Hotjar user analytics
- **`mixpanel`**: Mixpanel product analytics
- **`amplitude`**: Amplitude product analytics
- **`segment`**: Segment data pipeline
- **`google_analytics`**: Google Analytics integration
- **`adobe_analytics`**: Adobe Analytics integration

### Communication and Collaboration
- **`salesforce`**: Salesforce CRM integration
- **`hubspot`**: HubSpot CRM integration
- **`marketo`**: Marketo marketing automation
- **`pardot`**: Pardot marketing automation
- **`mailchimp`**: Mailchimp email marketing
- **`sendgrid`**: SendGrid email service
- **`twilio`**: Twilio communication platform
- **`vonage`**: Vonage communication APIs
- **`bandwidth`**: Bandwidth communication
- **`plivo`**: Plivo communication platform
- **`messagebird`**: MessageBird communication
- **`nexmo`**: Nexmo communication APIs
- **`pusher`**: Pusher real-time messaging
- **`pubnub`**: PubNub real-time infrastructure
- **`socket_io`**: Socket.IO real-time communication
- **`signalr`**: SignalR real-time web
- **`mqtt`**: MQTT messaging protocol
- **`amqp`**: AMQP messaging protocol
- **`rabbitmq`**: RabbitMQ message broker
- **`apache_kafka`**: Apache Kafka streaming
- **`apache_pulsar`**: Apache Pulsar messaging
- **`nats`**: NATS messaging system
- **`redis_streams`**: Redis Streams messaging

### Data Processing and Analytics
- **`apache_storm`**: Apache Storm stream processing
- **`apache_spark`**: Apache Spark big data processing
- **`apache_flink`**: Apache Flink stream processing
- **`apache_beam`**: Apache Beam data processing
- **`apache_airflow`**: Apache Airflow workflow management
- **`prefect`**: Prefect workflow orchestration
- **`dagster`**: Dagster data orchestration
- **`luigi`**: Luigi workflow management
- **`celery`**: Celery distributed task queue
- **`rq`**: RQ simple job queue
- **`sidekiq`**: Sidekiq background processing
- **`delayed_job`**: Delayed Job background processing
- **`good_job`**: Good Job background processing
- **`solid_queue`**: Solid Queue background processing
- **`faktory`**: Faktory work server
- **`machinery`**: Machinery distributed task queue
- **`asynq`**: Asynq distributed task queue
- **`riverqueue`**: River Queue job processing
- **`temporal`**: Temporal workflow engine
- **`cadence`**: Cadence workflow engine
- **`zeebe`**: Zeebe workflow engine
- **`camunda`**: Camunda workflow platform
- **`activiti`**: Activiti workflow engine
- **`flowable`**: Flowable workflow engine
- **`bonita`**: Bonita workflow platform
- **`drools`**: Drools business rules
- **`jbpm`**: jBPM workflow engine
- **`conductor`**: Conductor workflow orchestration
- **`argo`**: Argo workflow engine
- **`tekton`**: Tekton CI/CD pipelines

### Development Tools Integration
- **`jenkins`**: Jenkins CI/CD automation
- **`github_actions`**: GitHub Actions CI/CD
- **`gitlab_ci`**: GitLab CI/CD pipelines
- **`circleci`**: CircleCI continuous integration
- **`travis_ci`**: Travis CI continuous integration
- **`buildkite`**: Buildkite CI/CD platform
- **`teamcity`**: TeamCity CI/CD server
- **`bamboo`**: Bamboo CI/CD server
- **`azure_devops`**: Azure DevOps platform
- **`bitbucket`**: Bitbucket repository management
- **`sourcetree`**: SourceTree Git client
- **`gitkraken`**: GitKraken Git client
- **`smartgit`**: SmartGit client
- **`tower`**: Tower Git client
- **`fork`**: Fork Git client
- **`sublime_merge`**: Sublime Merge Git client
- **`vscode`**: Visual Studio Code integration
- **`intellij`**: IntelliJ IDEA integration
- **`eclipse`**: Eclipse IDE integration
- **`netbeans`**: NetBeans IDE integration
- **`atom`**: Atom editor integration
- **`brackets`**: Brackets editor integration
- **`notepad_plus`**: Notepad++ integration
- **`vim`**: Vim editor integration
- **`emacs`**: Emacs editor integration
- **`nano`**: Nano editor integration
- **`sublime_text`**: Sublime Text integration
- **`textmate`**: TextMate integration
- **`bbedit`**: BBEdit integration
- **`coderunner`**: CodeRunner integration
- **`xcode`**: Xcode integration
- **`android_studio`**: Android Studio integration

### Cross-Platform Development
- **`flutter`**: Flutter cross-platform development
- **`react_native`**: React Native development
- **`xamarin`**: Xamarin cross-platform development
- **`cordova`**: Apache Cordova hybrid apps
- **`phonegap`**: PhoneGap hybrid apps
- **`ionic`**: Ionic hybrid apps
- **`nativescript`**: NativeScript development
- **`electron`**: Electron desktop apps
- **`tauri`**: Tauri desktop apps
- **`neutralino`**: Neutralino desktop apps
- **`nwjs`**: NW.js desktop apps
- **`wails`**: Wails desktop apps
- **`fyne`**: Fyne desktop apps
- **`walk`**: Walk desktop apps
- **`lxn`**: LXN desktop apps
- **`qt`**: Qt cross-platform framework
- **`gtk`**: GTK+ toolkit
- **`tkinter`**: Tkinter Python GUI
- **`wxpython`**: wxPython GUI framework
- **`pyqt`**: PyQt GUI framework
- **`pyside`**: PySide GUI framework
- **`kivy`**: Kivy Python framework
- **`dear_imgui`**: Dear ImGui immediate mode GUI
- **`egui`**: egui immediate mode GUI
- **`iced`**: Iced GUI framework
- **`druid`**: Druid GUI framework
- **`slint`**: Slint GUI framework
- **`xilem`**: Xilem GUI framework
- **`dioxus`**: Dioxus web framework
- **`yew`**: Yew web framework
- **`percy`**: Percy web framework
- **`seed`**: Seed web framework
- **`sycamore`**: Sycamore web framework
- **`leptos`**: Leptos web framework

### WebAssembly and Web Technologies
- **`trunk`**: Trunk build tool
- **`wasm_pack`**: wasm-pack build tool
- **`wasm_bindgen`**: wasm-bindgen bindings
- **`js_sys`**: js-sys JavaScript bindings
- **`web_sys`**: web-sys Web API bindings
- **`wasm_game_of_life`**: WebAssembly game examples
- **`wee_alloc`**: wee_alloc memory allocator
- **`console_error_panic_hook`**: Error handling for WebAssembly
- **`wasm_logger`**: WebAssembly logging
- **`gloo`**: Gloo web framework utilities
- **`stdweb`**: stdweb web framework
- **`cargo_web`**: cargo-web build tool
- **`wasm_opt`**: WebAssembly optimization
- **`twiggy`**: WebAssembly code size profiler
- **`wasm_snip`**: WebAssembly snippet tool
- **`wasm_gc`**: WebAssembly garbage collection
- **`binaryen`**: Binaryen WebAssembly tools
- **`wasmtime`**: Wasmtime WebAssembly runtime
- **`wasmer`**: Wasmer WebAssembly runtime
- **`lucet`**: Lucet WebAssembly runtime
- **`wavm`**: WAVM WebAssembly runtime
- **`wasm3`**: WASM3 WebAssembly runtime
- **`wasmi`**: Wasmi WebAssembly interpreter
- **`cranelift`**: Cranelift code generation
- **`lightbeam`**: Lightbeam streaming compiler
- **`singlepass`**: Singlepass compiler

### GPU and Graphics Programming
- **`vulkan`**: Vulkan graphics API
- **`metal`**: Metal graphics API
- **`directx`**: DirectX graphics API
- **`opengl`**: OpenGL graphics API
- **`webgl`**: WebGL graphics API
- **`webgpu`**: WebGPU graphics API
- **`dawn`**: Dawn WebGPU implementation
- **`tint`**: Tint WGSL compiler
- **`skia`**: Skia graphics library
- **`cairo`**: Cairo graphics library
- **`pango`**: Pango text layout
- **`fontconfig`**: FontConfig font management
- **`freetype`**: FreeType font rendering
- **`harfbuzz`**: HarfBuzz text shaping
- **`llvm`**: LLVM compiler infrastructure
- **`mlir`**: MLIR compiler framework
- **`polly`**: Polly loop optimizer
- **`openmp`**: OpenMP parallel programming
- **`opencl`**: OpenCL parallel computing
- **`cuda`**: CUDA parallel computing
- **`rocm`**: ROCm compute platform

### Text Processing and Internationalization
- **`icu`**: ICU internationalization library
- **`unicode`**: Unicode text processing
- **`utf8`**: UTF-8 encoding support
- **`utf16`**: UTF-16 encoding support
- **`utf32`**: UTF-32 encoding support
- **`ascii`**: ASCII encoding support
- **`latin1`**: Latin-1 encoding support
- **`cp1252`**: CP-1252 encoding support
- **`iso8859`**: ISO-8859 encoding family
- **`big5`**: Big5 encoding support
- **`gb2312`**: GB2312 encoding support
- **`gbk`**: GBK encoding support
- **`gb18030`**: GB18030 encoding support
- **`shift_jis`**: Shift JIS encoding support
- **`euc_jp`**: EUC-JP encoding support
- **`euc_kr`**: EUC-KR encoding support
- **`koi8_r`**: KOI8-R encoding support
- **`windows_1251`**: Windows-1251 encoding support
- **`iso8859_5`**: ISO-8859-5 encoding support
- **`macroman`**: MacRoman encoding support
- **`ebcdic`**: EBCDIC encoding support
- **`punycode`**: Punycode encoding support
- **`idna`**: IDNA domain name encoding
- **`base64`**: Base64 encoding support
- **`base32`**: Base32 encoding support
- **`base16`**: Base16 encoding support
- **`hex`**: Hexadecimal encoding support
- **`url_encoding`**: URL encoding support
- **`percent_encoding`**: Percent encoding support
- **`html_entities`**: HTML entity encoding
- **`xml_entities`**: XML entity encoding
- **`json_escape`**: JSON string escaping
- **`csv_escape`**: CSV field escaping
- **`sql_escape`**: SQL string escaping
- **`regex`**: Regular expression support
- **`glob`**: Glob pattern matching
- **`fuzzy_matching`**: Fuzzy string matching

### String Similarity and Distance Algorithms
- **`levenshtein`**: Levenshtein distance algorithm
- **`soundex`**: Soundex phonetic algorithm
- **`metaphone`**: Metaphone phonetic algorithm
- **`double_metaphone`**: Double Metaphone algorithm
- **`nysiis`**: NYSIIS phonetic algorithm
- **`match_rating`**: Match Rating Approach
- **`jaro`**: Jaro string similarity
- **`jaro_winkler`**: Jaro-Winkler similarity
- **`jaccard`**: Jaccard similarity coefficient
- **`cosine`**: Cosine similarity
- **`euclidean`**: Euclidean distance
- **`manhattan`**: Manhattan distance
- **`hamming`**: Hamming distance
- **`minkowski`**: Minkowski distance
- **`chebyshev`**: Chebyshev distance
- **`braycurtis`**: Bray-Curtis distance
- **`canberra`**: Canberra distance
- **`correlation`**: Correlation distance
- **`chi_squared`**: Chi-squared distance
- **`kullback_leibler`**: Kullback-Leibler divergence
- **`jensen_shannon`**: Jensen-Shannon divergence
- **`mutual_information`**: Mutual information
- **`normalized_mutual_information`**: Normalized mutual information
- **`adjusted_mutual_information`**: Adjusted mutual information
- **`adjusted_rand_index`**: Adjusted Rand index
- **`homogeneity`**: Homogeneity score
- **`completeness`**: Completeness score
- **`v_measure`**: V-measure score
- **`silhouette`**: Silhouette coefficient
- **`calinski_harabasz`**: Calinski-Harabasz index
- **`davies_bouldin`**: Davies-Bouldin index
- **`dunn`**: Dunn index
- **`xie_beni`**: Xie-Beni index

### Machine Learning Metrics and Evaluation
- **`within_cluster_sum_of_squares`**: Within-cluster sum of squares
- **`between_cluster_sum_of_squares`**: Between-cluster sum of squares
- **`total_sum_of_squares`**: Total sum of squares
- **`explained_variance`**: Explained variance score
- **`mean_squared_error`**: Mean squared error
- **`root_mean_squared_error`**: Root mean squared error
- **`mean_absolute_error`**: Mean absolute error
- **`median_absolute_error`**: Median absolute error
- **`r2_score`**: RÂ² coefficient of determination
- **`adjusted_r2_score`**: Adjusted RÂ² score
- **`accuracy`**: Classification accuracy
- **`precision`**: Precision score
- **`recall`**: Recall score
- **`f1_score`**: F1 score
- **`f_beta_score`**: F-beta score
- **`roc_auc`**: ROC AUC score
- **`pr_auc`**: Precision-Recall AUC
- **`log_loss`**: Logarithmic loss
- **`hinge_loss`**: Hinge loss
- **`huber_loss`**: Huber loss
- **`quantile_loss`**: Quantile loss
- **`pinball_loss`**: Pinball loss
- **`epsilon_insensitive_loss`**: Epsilon-insensitive loss
- **`squared_hinge_loss`**: Squared hinge loss
- **`modified_huber_loss`**: Modified Huber loss
- **`perceptron_loss`**: Perceptron loss
- **`squared_loss`**: Squared loss
- **`absolute_loss`**: Absolute loss
- **`exponential_loss`**: Exponential loss
- **`deviance_loss`**: Deviance loss
- **`poisson_loss`**: Poisson loss
- **`gamma_loss`**: Gamma loss
- **`tweedie_loss`**: Tweedie loss
- **`cox_loss`**: Cox loss
- **`survival_analysis`**: Survival analysis
- **`time_series_analysis`**: Time series analysis
- **`forecasting`**: Time series forecasting
- **`seasonal_decomposition`**: Seasonal decomposition
- **`trend_analysis`**: Trend analysis
- **`anomaly_detection_ts`**: Time series anomaly detection
- **`change_point_detection`**: Change point detection
- **`outlier_detection`**: Outlier detection
- **`novelty_detection`**: Novelty detection
- **`one_class_svm`**: One-class SVM
- **`isolation_forest`**: Isolation Forest
- **`local_outlier_factor`**: Local Outlier Factor
- **`elliptic_envelope`**: Elliptic Envelope
- **`robust_covariance`**: Robust covariance estimation
- **`minimum_covariance_determinant`**: Minimum covariance determinant
- **`empirical_covariance`**: Empirical covariance
- **`graphical_lasso`**: Graphical Lasso
- **`ledoit_wolf`**: Ledoit-Wolf shrinkage
- **`oas`**: Oracle Approximating Shrinkage
- **`shrunk_covariance`**: Shrunk covariance

### Dimensionality Reduction and Manifold Learning
- **`pca`**: Principal Component Analysis
- **`kernel_pca`**: Kernel PCA
- **`sparse_pca`**: Sparse PCA
- **`incremental_pca`**: Incremental PCA
- **`factor_analysis`**: Factor Analysis
- **`fastica`**: FastICA
- **`dictionary_learning`**: Dictionary Learning
- **`mini_batch_dictionary_learning`**: Mini-batch Dictionary Learning
- **`non_negative_matrix_factorization`**: Non-negative Matrix Factorization
- **`latent_dirichlet_allocation`**: Latent Dirichlet Allocation
- **`independent_component_analysis`**: Independent Component Analysis
- **`canonical_correlation_analysis`**: Canonical Correlation Analysis
- **`partial_least_squares`**: Partial Least Squares
- **`multidimensional_scaling`**: Multidimensional Scaling
- **`isomap`**: Isomap
- **`locally_linear_embedding`**: Locally Linear Embedding
- **`modified_locally_linear_embedding`**: Modified Locally Linear Embedding
- **`hessian_eigenmapping`**: Hessian Eigenmapping
- **`spectral_embedding`**: Spectral Embedding
- **`t_sne`**: t-SNE
- **`umap`**: UMAP
- **`phate`**: PHATE
- **`trimap`**: TriMap
- **`pacmap`**: PaCMAP
- **`force_atlas_2`**: Force Atlas 2
- **`fruchterman_reingold`**: Fruchterman-Reingold
- **`kamada_kawai`**: Kamada-Kawai
- **`spring_layout`**: Spring Layout
- **`circular_layout`**: Circular Layout
- **`random_layout`**: Random Layout
- **`shell_layout`**: Shell Layout
- **`spectral_layout`**: Spectral Layout
- **`planar_layout`**: Planar Layout
- **`bipartite_layout`**: Bipartite Layout
- **`multipartite_layout`**: Multipartite Layout
- **`rescale_layout`**: Rescale Layout
- **`rescale_layout_dict`**: Rescale Layout Dictionary

### Graph Analysis and Network Science
- **`drawing`**: Graph drawing algorithms
- **`networkx`**: NetworkX graph analysis
- **`igraph`**: igraph graph analysis
- **`graph_tool`**: graph-tool analysis
- **`networkit`**: NetworKit graph analysis
- **`snap`**: SNAP graph analysis
- **`boost_graph`**: Boost Graph Library
- **`petgraph`**: petgraph Rust library
- **`graphlib`**: graphlib Python library
- **`rustworkx`**: rustworkx Rust library

### Visualization and Plotting
- **`plotly`**: Plotly interactive visualizations
- **`bokeh`**: Bokeh web-based visualizations
- **`matplotlib`**: Matplotlib plotting library
- **`seaborn`**: Seaborn statistical visualization
- **`altair`**: Altair declarative visualization
- **`plotnine`**: plotnine grammar of graphics
- **`ggplot2`**: ggplot2 grammar of graphics
- **`lattice`**: Lattice graphics system
- **`base_graphics`**: Base graphics system
- **`grid`**: Grid graphics system
- **`cowplot`**: cowplot publication-ready plots
- **`patchwork`**: patchwork plot composition
- **`gganimate`**: gganimate animated plots
- **`plotly_r`**: Plotly R integration
- **`dygraphs`**: dygraphs time series plots
- **`leaflet`**: Leaflet interactive maps
- **`mapview`**: mapview interactive maps
- **`tmap`**: tmap thematic maps
- **`sf`**: sf spatial features
- **`sp`**: sp spatial classes
- **`rgdal`**: rgdal geospatial abstraction
- **`raster`**: raster geographic data
- **`terra`**: terra spatial data
- **`stars`**: stars spatiotemporal arrays
- **`maptools`**: maptools spatial utilities
- **`rgeos`**: rgeos geometry engine
- **`geosphere`**: geosphere spherical geometry
- **`geodist`**: geodist distance calculations
- **`osmdata`**: osmdata OpenStreetMap data
- **`tidygeocoder`**: tidygeocoder geocoding
- **`opencage`**: opencage geocoding
- **`nominatim`**: Nominatim geocoding

### Mapping and Location Services
- **`google_maps`**: Google Maps integration
- **`mapbox`**: Mapbox mapping platform
- **`openstreetmap`**: OpenStreetMap integration
- **`stamen`**: Stamen map tiles
- **`cartodb`**: CartoDB mapping platform
- **`esri`**: Esri mapping services
- **`here`**: HERE mapping platform
- **`tomtom`**: TomTom mapping services
- **`mapquest`**: MapQuest mapping services
- **`bing_maps`**: Bing Maps integration
- **`yandex_maps`**: Yandex Maps integration
- **`baidu_maps`**: Baidu Maps integration
- **`amap`**: Amap mapping services
- **`naver_maps`**: Naver Maps integration
- **`kakao_maps`**: Kakao Maps integration
- **`apple_maps`**: Apple Maps integration
- **`waze`**: Waze navigation integration
- **`uber`**: Uber ride-sharing integration
- **`lyft`**: Lyft ride-sharing integration
- **`didi`**: Didi ride-sharing integration
- **`grab`**: Grab ride-sharing integration
- **`gojek`**: Gojek ride-sharing integration
- **`ola`**: Ola ride-sharing integration
- **`bolt`**: Bolt ride-sharing integration
- **`via`**: Via ride-sharing integration
- **`citymapper`**: Citymapper transit integration
- **`moovit`**: Moovit transit integration
- **`transit`**: Transit app integration
- **`google_transit`**: Google Transit integration
- **`apple_transit`**: Apple Transit integration
- **`microsoft_transit`**: Microsoft Transit integration

### Location-Based Services and Travel
- **`foursquare`**: Foursquare location platform
- **`swarm`**: Swarm check-in app
- **`yelp`**: Yelp business directory
- **`google_places`**: Google Places API
- **`facebook_places`**: Facebook Places integration
- **`tripadvisor`**: TripAdvisor travel platform
- **`booking`**: Booking.com accommodation
- **`expedia`**: Expedia travel platform
- **`airbnb`**: Airbnb accommodation
- **`vrbo`**: VRBO vacation rentals
- **`homeaway`**: HomeAway vacation rentals
- **`hotels_com`**: Hotels.com accommodation
- **`agoda`**: Agoda hotel booking
- **`priceline`**: Priceline travel booking
- **`kayak`**: Kayak travel search
- **`skyscanner`**: Skyscanner flight search
- **`momondo`**: Momondo travel search
- **`hipmunk`**: Hipmunk travel search
- **`orbitz`**: Orbitz travel booking
- **`travelocity`**: Travelocity travel booking
- **`cheaptickets`**: CheapTickets booking
- **`onetravel`**: OneTravel booking
- **`cheapoair`**: CheapOair booking
- **`studentuniverse`**: StudentUniverse booking
- **`sta_travel`**: STA Travel booking
- **`flight_centre`**: Flight Centre booking
- **`lastminute`**: Lastminute.com booking
- **`opodo`**: Opodo travel booking
- **`ebookers`**: eBookers travel booking
- **`gotogate`**: Gotogate booking
- **`budgetair`**: BudgetAir booking
- **`bravofly`**: Bravofly booking
- **`volagratis`**: Volagratis booking
- **`rumbo`**: Rumbo travel booking
- **`edreams`**: eDreams travel booking
- **`go_voyages`**: Go Voyages booking
- **`liligo`**: Liligo travel search
- **`jetcost`**: Jetcost travel search
- **`wego`**: Wego travel search
- **`skypicker`**: Skypicker booking
- **`kiwi`**: Kiwi.com booking
- **`scott_cheap_flights`**: Scott's Cheap Flights
- **`secret_flying`**: Secret Flying deals
- **`the_flight_deal`**: The Flight Deal
- **`google_flights`**: Google Flights search
- **`bing_travel`**: Bing Travel search
- **`yahoo_travel`**: Yahoo Travel search
- **`apple_travel`**: Apple Travel integration
- **`microsoft_travel`**: Microsoft Travel integration
- **`amazon_travel`**: Amazon Travel integration
- **`facebook_travel`**: Facebook Travel integration
- **`instagram_travel`**: Instagram Travel integration
- **`twitter_travel`**: Twitter Travel integration
- **`linkedin_travel`**: LinkedIn Travel integration
- **`pinterest_travel`**: Pinterest Travel integration
- **`reddit_travel`**: Reddit Travel integration
- **`youtube_travel`**: YouTube Travel integration
- **`tiktok_travel`**: TikTok Travel integration
- **`snapchat_travel`**: Snapchat Travel integration
- **`whatsapp_travel`**: WhatsApp Travel integration
- **`telegram_travel`**: Telegram Travel integration
- **`signal_travel`**: Signal Travel integration
- **`discord_travel`**: Discord Travel integration
- **`slack_travel`**: Slack Travel integration
- **`teams_travel`**: Teams Travel integration
- **`zoom_travel`**: Zoom Travel integration
- **`skype_travel`**: Skype Travel integration
- **`facetime_travel`**: FaceTime Travel integration
- **`google_meet_travel`**: Google Meet Travel integration
- **`webex_travel`**: Webex Travel integration
- **`gotomeeting_travel`**: GoToMeeting Travel integration
- **`bluejeans_travel`**: BlueJeans Travel integration
- **`jitsi_travel`**: Jitsi Travel integration
- **`big_blue_button_travel`**: BigBlueButton Travel integration
- **`whereby_travel`**: Whereby Travel integration
- **`around_travel`**: Around Travel integration
- **`mmhmm_travel`**: mmhmm Travel integration
- **`riverside_travel`**: Riverside Travel integration
- **`squadcast_travel`**: SquadCast Travel integration
- **`zencastr_travel`**: Zencastr Travel integration

### Media and Entertainment Services
- **`anchor_travel`**: Anchor Travel integration
- **`spotify_travel`**: Spotify Travel integration
- **`apple_podcasts_travel`**: Apple Podcasts Travel integration
- **`google_podcasts_travel`**: Google Podcasts Travel integration
- **`stitcher_travel`**: Stitcher Travel integration
- **`overcast_travel`**: Overcast Travel integration
- **`pocket_casts_travel`**: Pocket Casts Travel integration
- **`castro_travel`**: Castro Travel integration
- **`downcast_travel`**: Downcast Travel integration
- **`podcast_addict_travel`**: Podcast Addict Travel integration
- **`podbean_travel`**: Podbean Travel integration
- **`buzzsprout_travel`**: Buzzsprout Travel integration
- **`libsyn_travel`**: Libsyn Travel integration
- **`soundcloud_travel`**: SoundCloud Travel integration
- **`mixcloud_travel`**: Mixcloud Travel integration
- **`bandcamp_travel`**: Bandcamp Travel integration
- **`lastfm_travel`**: Last.fm Travel integration
- **`pandora_travel`**: Pandora Travel integration
- **`iheart_travel`**: iHeart Travel integration
- **`tunein_travel`**: TuneIn Travel integration
- **`radio_com_travel`**: Radio.com Travel integration
- **`audible_travel`**: Audible Travel integration
- **`scribd_travel`**: Scribd Travel integration
- **`kindle_travel`**: Kindle Travel integration
- **`kobo_travel`**: Kobo Travel integration
- **`nook_travel`**: Nook Travel integration
- **`google_books_travel`**: Google Books Travel integration
- **`apple_books_travel`**: Apple Books Travel integration
- **`amazon_books_travel`**: Amazon Books Travel integration
- **`goodreads_travel`**: Goodreads Travel integration
- **`shelfari_travel`**: Shelfari Travel integration
- **`librarything_travel`**: LibraryThing Travel integration
- **`anobii_travel`**: Anobii Travel integration
- **`bookish_travel`**: Bookish Travel integration
- **`douban_travel`**: Douban Travel integration

### Extended Device and Platform Support
These features cover an extensive range of devices, platforms, and services that might be integrated with AR glasses in the future:

- **Gaming Console Integration**: PS5, Xbox Series, Nintendo Switch, Steam Deck
- **Smart TV Integration**: Apple TV, Roku, Chromecast, Fire TV, Android TV, WebOS TV, Tizen TV
- **IoT Device Integration**: Smart home devices, wearables, sensors
- **Audio Format Support**: MP3, FLAC, WAV, AIFF, OGG, Opus, AAC, M4A, WMA
- **Video Format Support**: MP4, AVI, MKV, WebM, MOV, RMVB, FLV, 3GP
- **Archive Format Support**: ZIP, RAR, 7Z, TAR, GZ, BZ2, XZ
- **Document Format Support**: PDF, DOC, DOCX, XLS, XLSX, PPT, PPTX
- **Image Format Support**: PNG, JPG, GIF, WebP, TIFF, BMP, SVG
- **Network Protocol Support**: TCP, UDP, HTTP, HTTPS, WebSocket, gRPC, MQTT
- **Security Protocol Support**: TLS, SSL, OAuth, JWT, SAML, LDAP
- **Database Support**: MySQL, PostgreSQL, SQLite, MongoDB, Redis, CouchDB
- **Message Queue Support**: RabbitMQ, Apache Kafka, Redis Pub/Sub, NATS
- **Container Support**: Docker, Kubernetes, OpenShift, Nomad
- **Virtualization Support**: VMware, VirtualBox, KVM, Xen, Hyper-V
- **Monitoring Support**: Prometheus, Grafana, Datadog, New Relic, Splunk

## Usage Recommendations

### Essential Features for AR Virtual Desktop
```toml
# Core minimum required features
features = [
    "nreal", "rokid", "mad_gaze", "grawoow",  # Hardware support
    "rusb", "hidapi", "libusb",              # Communication
    "async", "zerocopy", "simd",             # Performance
    "stereo", "tracking", "sensors",         # AR functionality
    "debug", "profiling"                     # Development
]
```

### Recommended Features for Production
```toml
# Production-ready feature set
features = [
    # Core hardware and communication
    "nreal", "rokid", "mad_gaze", "grawoow", "rusb", "hidapi", "libusb", "hotplug",
    
    # Performance and optimization
    "async", "zerocopy", "simd", "benchmark", "profiling",
    
    # AR/VR functionality
    "stereo", "tracking", "sensors", "calibration", "eye_tracking", "hand_tracking",
    
    # Advanced features
    "spatial_audio", "computer_vision", "slam", "persistence", "multiplayer",
    
    # Platform support
    "macos", "windows", "linux", "android",
    
    # Security and enterprise
    "security", "encryption", "authentication", "enterprise",
    
    # Development and debugging
    "debug", "trace", "mock", "simulator", "telemetry", "diagnostics"
]
```

### Future-Proofing Feature Set
```toml
# Comprehensive feature set for long-term compatibility
features = [
    # All current hardware
    "nreal", "rokid", "mad_gaze", "grawoow",
    
    # Future hardware support
    "apple_vision", "meta_quest", "varjo", "magic_leap", "hololens",
    
    # All communication protocols
    "rusb", "hidapi", "serialport", "libusb", "hotplug", "udev",
    
    # All performance features
    "async", "zerocopy", "simd", "benchmark", "profiling",
    
    # All AR/VR features
    "stereo", "tracking", "sensors", "calibration", "passthrough", "camera",
    "eye_tracking", "hand_tracking", "facial_tracking", "voice_commands",
    "gesture_recognition", "spatial_audio", "haptic_feedback",
    
    # All AI/ML features
    "ai_acceleration", "neural_processing", "computer_vision", "machine_learning",
    "deep_learning", "object_detection", "face_recognition", "nlp",
    
    # All connectivity
    "wireless", "bluetooth", "wifi_direct", "5g", "edge_computing",
    
    # All platform support
    "macos", "windows", "linux", "android", "ios",
    
    # All security features
    "security", "encryption", "authentication", "authorization", "privacy",
    
    # All enterprise features
    "enterprise", "mdm", "compliance", "audit_logging", "single_sign_on",
    
    # All cloud integration
    "aws", "azure", "gcp", "cloud_rendering", "cloud_sync",
    
    # All development tools
    "debug", "trace", "mock", "simulator", "telemetry", "diagnostics", "sdk", "api"
]
```

This comprehensive feature reference ensures that your AR virtual desktop platform can support the widest possible range of AR glasses hardware, advanced functionality, and future expansion capabilities while maintaining optimal performance and security standards.